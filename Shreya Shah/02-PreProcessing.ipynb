{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating and running the models on the articles, some preprocessing is needed first so that the models run efficiently. Here, this includes some general cleaning of the original dataset, tokenisation and removing stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shah_\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "news = pd.read_csv('news-data.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Dome...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category filename                              title  \\\n",
       "0  business  001.txt  Ad sales boost Time Warner profit   \n",
       "1  business  002.txt   Dollar gains on Greenspan speech   \n",
       "2  business  003.txt  Yukos unit buyer faces loan claim   \n",
       "3  business  004.txt  High fuel prices hit BA's profits   \n",
       "4  business  005.txt  Pernod takeover talk lifts Domecq   \n",
       "\n",
       "                                             content  \n",
       "0   Quarterly profits at US media giant TimeWarne...  \n",
       "1   The dollar has hit its highest level against ...  \n",
       "2   The owners of embattled Russian oil giant Yuk...  \n",
       "3   British Airways has blamed high fuel prices f...  \n",
       "4   Shares in UK drinks and food firm Allied Dome...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we carry out tokenisation. This comprises of separating the content of the articles into individual words, turning any uppercase letters into lowercase letters and removing any punctuation or generally any non-letter characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "839464\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "all_words = []\n",
    "\n",
    "for i in range(len(news[\"content\"])):\n",
    "    all_words.append(news[\"content\"][i].split())\n",
    "print(all_words[1])\n",
    "'''\n",
    "\n",
    "all_words = \"\"\n",
    "print(len(news[\"content\"]))\n",
    "lowercase_content = []\n",
    "full_clean = []\n",
    "\n",
    "for i in range(len(news[\"content\"])):\n",
    "    current = news[\"content\"][i]\n",
    "    clean = current.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    clean = clean.replace('Â£', '')\n",
    "    full_clean.append(clean.split())\n",
    "    lowercase_content.append(clean)\n",
    "    all_words = all_words + clean + \" \"\n",
    "\n",
    "#print(lowercase_content[2:5])\n",
    "final = all_words.split()\n",
    "total_count = len(final)\n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['464000', 'subscribers', 'in', 'the', 'fourth', 'quarter', 'profits', 'were', 'lower', 'than', 'in', 'the', 'preceding', 'three', 'quarters', 'however', 'the', 'company', 'said', 'aols', 'underlying', 'profit', 'before', 'exceptional', 'items', 'rose', '8', 'on', 'the', 'back', 'of', 'stronger', 'internet', 'advertising', 'revenues', 'it', 'hopes', 'to', 'increase', 'subscribers', 'by', 'offering', 'the', 'online', 'service', 'free', 'to', 'timewarner', 'internet', 'customers', 'and', 'will', 'try', 'to', 'sign', 'up', 'aols', 'existing', 'customers', 'for', 'highspeed', 'broadband', 'timewarner', 'also', 'has', 'to', 'restate', '2000', 'and', '2003', 'results', 'following', 'a', 'probe', 'by', 'the', 'us', 'securities', 'exchange', 'commission', 'sec', 'which', 'is', 'close', 'to', 'concluding', 'time', 'warners', 'fourth', 'quarter', 'profits', 'were', 'slightly', 'better', 'than', 'analysts', 'expectations', 'but', 'its', 'film']\n"
     ]
    }
   ],
   "source": [
    "print(final[100:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we count the frequency of each word in the data set. With this, we can determine what the stop words should be, which will then be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "count = Counter(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq = count.items()\n",
    "# As the next line of code prints every word in all of the articles with their frequencies,\n",
    "# it has been commented out to make the notebook more presentable\n",
    "\n",
    "#print(sorted(freq, key=lambda value: value[1], reverse = True))\n",
    "#print(count.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words are words that have no discernable relation to any topic, such as \"the\", \"or\", etc. The stopwords will be manually chosen and put into the file stopwords.txt. From there, they will be read and put in the list stopwords_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'to', 'of', 'and', 'a', 'in', 'for', 'is', 'that', 'on', 'said', 'it', 'was', 'he', 'be', 'with', 'as', 'has', 'have', 'at', 'will', 'by', 'but', 'are', 'from', 'not', 'i', 'its', 'his', 'mr', 'they', 'this', 'an', 'we', 'which', 'had', 'would', 'been', 'their', 'were', 'more', 'also', 'who', 'people', 'up', 'new', 'about', 'us', 'there', 'one', 'after', 'or', 'than', 'year', 'out', 'can', 'all', 'if', 'could', 'you', 'last', 'over', 'when', 'first', 'year', 'two', 'time', 'now', 'other', 'some', 'into', 'what', 'she', 'so', 'them', 'against', 'just', 'do', 'only', 'no', 'best', 'being', 'make', 'told', 'get', 'such', 'made', 'very', 'like', 'many', 'should', 'because', 'before', 'while', 'her', 'next', 'three', 'any', 'most', 'back', 'well', 'added', 'way', 'take', 'my', 'our', 'may', 'say', 'good', 'him', 'how', 'then', 'going', 'those', 'still', 'much', 'down', 'since', 'go', 'use', 'say', 'million', 'want', 'off', 'between', 'see', 'show', 'did', 'week', 'used', 'where', 'under', 'even', 'five', 'already', 'put', 'come', 'me', 'during', 'six', 'too', 'four', 'dont', '10', '2005', 'including', 'around', 'big', 'great', 'really', 'another', '2003', 'got', 'move', 'im', 'took', 'same', 'third', 'came', 'know', 'despite']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove stop words\n",
    "with open('stopwords.txt') as f:\n",
    "    stopwords = f.read()\n",
    "\n",
    "stopwords_list = stopwords.split()\n",
    "print(stopwords.split())\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_there(s):\n",
    "    return any(i.isdigit() for i in s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code removes any stopwords and numbers from the tokenised articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "417238\n"
     ]
    }
   ],
   "source": [
    "#current = lowercase_content[1]\n",
    "#regex = 'the'\n",
    "#re.sub(regex,'',current)\n",
    "clean_filtered = []\n",
    "post_count = 0\n",
    "print(len(full_clean))\n",
    "for i in range(len(full_clean)):\n",
    "    filtered = full_clean[i]\n",
    "    for j in range(len(stopwords_list)):\n",
    "        filtered = [i for i in filtered if (stopwords_list[j] != i) and (not num_there(i))]\n",
    "    post_count += len(filtered)\n",
    "    \n",
    "    if(i % 100 == 0):\n",
    "        print(i)\n",
    "    \n",
    "    clean_filtered.append(' '.join(filtered))\n",
    "print(post_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.702905663613926\n"
     ]
    }
   ],
   "source": [
    "print(post_count / total_count * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above number is the percentage of words that remain after stopwords have been removed, so over half have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['owners embattled russian oil giant yukos ask buyer former production unit pay loan stateowned rosneft bought yugansk unit sale forced russia part settle tax claim yukos yukos owner menatep group says ask rosneft repay loan yugansk secured assets rosneft faces similar repayment demand foreign banks legal experts rosnefts purchase yugansk include obligations pledged assets rosneft pay real money creditors avoid seizure yugansk assets moscowbased lawyer jamie firestone connected case menatep groups managing director tim osborne reuters news agency default fight rule law exists international arbitration clauses credit rosneft officials unavailable comment company intends action menatep recover tax claims debts owed yugansk yukos filed bankruptcy protection court attempt prevent forced sale main production arm sale went ahead december yugansk sold littleknown shell company turn bought rosneft yukos claims downfall punishment political ambitions founder mikhail khodorkovsky vowed sue participant sale', 'british airways blamed high fuel prices drop profits reporting results months december airline pretax profit compared earlier rod eddington bas chief executive results respectable quarter fuel costs rose bas profits better market expectation expects rise fullyear revenues help offset increased price aviation fuel ba introduced fuel surcharge passengers october increased oneway longhaul flights shorthaul surcharge raised leg yet aviation analyst mike powell dresdner kleinwort wasserstein says bas estimated annual surcharge revenues short additional fuel costs predicted extra turnover quarter further benefiting rise cargo revenue looking ahead full results march ba warned yields average revenues per passenger expected decline continues lower prices face competition lowcost carriers however sales better previously forecast march total revenue outlook slightly better previous guidance improvement anticipated ba chairman martin broughton ba previously forecast rise fullyear revenue reported friday passenger numbers rose january aviation analyst nick van den brul bnp paribas described bas latest quarterly results pretty modest quite revenue side shows impact fuel surcharges positive cargo development however operating margins cost impact fuel strong september attacks united states ba cut jobs part major costcutting drive focus remains reducing controllable costs debt whilst continuing invest products eddington example taken delivery airbus aircraft month start further improvements club world flat beds bas shares closed pence pence']\n"
     ]
    }
   ],
   "source": [
    "print(clean_filtered[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the strings and a complete vocabulary list and turn them into .csv files. We include only the category and the preprocessed content of each article, the original filename and titles have been omitted as these are not necessary for the models to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(clean_filtered, columns = ['string'])\n",
    "df.insert(0,\"category\", news[\"category\"])\n",
    "df[\"category\"] = news[\"category\"]\n",
    "df.to_csv('cleaned_strings.csv', sep=\",\", index=True)\n",
    "df.to_csv('removed.csv', sep =\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(stopwords_list)):\n",
    "    final = [i for i in final if stopwords_list[j] != i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_list = list(set(final))\n",
    "df2 = pd.DataFrame(entire_list)\n",
    "df2.to_csv('allwords.csv', sep =\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
