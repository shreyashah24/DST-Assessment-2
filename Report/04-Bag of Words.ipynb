{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b1ecb7",
   "metadata": {},
   "source": [
    "# Bag of Words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f05bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt, exp, pi\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ae4f0",
   "metadata": {},
   "source": [
    "First must import the training and test dataset then separate the category column from the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d7ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('C:/Users/Calvi/Documents/Uni/Data Science Toolbox/Assessment 2/articles_train_90_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6661a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_test = pd.read_csv('C:/Users/Calvi/Documents/Uni/Data Science Toolbox/Assessment 2/articles_test_90_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8f56ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_test_Categories = articles_test['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b931d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_test_string = articles_test['string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdb6e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category</th>\n",
       "      <th>string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>business</td>\n",
       "      <td>quarterly profits media giant timewarner jumpe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>dollar hit highest level euro almost months fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>business</td>\n",
       "      <td>owners embattled russian oil giant yukos ask b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>business</td>\n",
       "      <td>shares uk drinks food firm allied domecq risen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>business</td>\n",
       "      <td>japans economy teetered brink technical recess...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  category                                             string\n",
       "0           0  business  quarterly profits media giant timewarner jumpe...\n",
       "1           1  business  dollar hit highest level euro almost months fe...\n",
       "2           2  business  owners embattled russian oil giant yukos ask b...\n",
       "3           4  business  shares uk drinks food firm allied domecq risen...\n",
       "4           5  business  japans economy teetered brink technical recess..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "540628ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_wc = np.array(articles['string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2fef5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ws(text):\n",
    "    # This function turns a piece of text into a list of the words within that text\n",
    "    list = []\n",
    "    for i in text:\n",
    "        list.append(str(i).split())\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d080adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_ws = remove_ws(articles_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02dc3fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab():\n",
    "    # This gathers all of the words mentioned in the documents and geta list of the unique ones\n",
    "    vocab = []\n",
    "    for i in np.array(pd.read_csv('C:/Users/Calvi/Documents/Uni/Data Science Toolbox/Assessment 2/allwords.csv')).T[0]:\n",
    "        if i not in vocab:\n",
    "            vocab.append(i)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc176494",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2fac7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [x for x in vocab if not any(c.isdigit() for c in str(x))] # This removes every number mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b397a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordtovec(text):\n",
    "    # changes a list of words to a list of numbers where each one represented the number of times a certain word in vocab() is mentioned\n",
    "    vector = []\n",
    "    for word in vocab:\n",
    "        vector.append(text.count(word))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eb654f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordtomat(text):\n",
    "    # changes an array of lists of words to an array of lists of numbers where each row represent a text and each number in a row represent the number of times a certain word in vocab() is mentioned \n",
    "    vector = []\n",
    "    counter = 0\n",
    "    for article in text:\n",
    "        vector.append(wordtovec(article))\n",
    "        counter += 1\n",
    "        \n",
    "        if counter % 1000 == 0:\n",
    "            print(counter)\n",
    "    return vector  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e1cc00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "bagofwords = wordtomat(articles_ws)\n",
    "bagofwords_df = pd.DataFrame(bagofwords, columns = vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ff8ca0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foreignlanguage</th>\n",
       "      <th>milton</th>\n",
       "      <th>licensing</th>\n",
       "      <th>orders</th>\n",
       "      <th>matthew</th>\n",
       "      <th>annette</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>fergus</th>\n",
       "      <th>investments</th>\n",
       "      <th>filmmaking</th>\n",
       "      <th>...</th>\n",
       "      <th>administrator</th>\n",
       "      <th>nonus</th>\n",
       "      <th>infections</th>\n",
       "      <th>mbeki</th>\n",
       "      <th>illequipped</th>\n",
       "      <th>recognise</th>\n",
       "      <th>nowadays</th>\n",
       "      <th>dismounting</th>\n",
       "      <th>xabi</th>\n",
       "      <th>tossed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   foreignlanguage  milton  licensing  orders  matthew  annette  broadcast  \\\n",
       "0                0       0          0       0        0        0          0   \n",
       "1                0       0          0       0        0        0          0   \n",
       "2                0       0          0       0        0        0          0   \n",
       "3                0       0          0       0        0        0          0   \n",
       "4                0       0          0       0        0        0          0   \n",
       "\n",
       "   fergus  investments  filmmaking  ...  administrator  nonus  infections  \\\n",
       "0       0            0           0  ...              0      0           0   \n",
       "1       0            0           0  ...              0      0           0   \n",
       "2       0            0           0  ...              0      0           0   \n",
       "3       0            0           0  ...              0      0           0   \n",
       "4       0            0           0  ...              0      0           0   \n",
       "\n",
       "   mbeki  illequipped  recognise  nowadays  dismounting  xabi  tossed  \n",
       "0      0            0          0         0            0     0       0  \n",
       "1      0            0          0         0            0     0       0  \n",
       "2      0            0          0         0            0     0       0  \n",
       "3      0            0          0         0            0     0       0  \n",
       "4      0            0          0         0            0     0       0  \n",
       "\n",
       "[5 rows x 31120 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagofwords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e6a904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = pd.DataFrame(preprocessing.LabelEncoder().fit_transform(articles['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85dc39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.columns=['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "967318e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagofwords_and_cat = pd.concat([bagofwords_df,y1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b076031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foreignlanguage</th>\n",
       "      <th>milton</th>\n",
       "      <th>licensing</th>\n",
       "      <th>orders</th>\n",
       "      <th>matthew</th>\n",
       "      <th>annette</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>fergus</th>\n",
       "      <th>investments</th>\n",
       "      <th>filmmaking</th>\n",
       "      <th>...</th>\n",
       "      <th>nonus</th>\n",
       "      <th>infections</th>\n",
       "      <th>mbeki</th>\n",
       "      <th>illequipped</th>\n",
       "      <th>recognise</th>\n",
       "      <th>nowadays</th>\n",
       "      <th>dismounting</th>\n",
       "      <th>xabi</th>\n",
       "      <th>tossed</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   foreignlanguage  milton  licensing  orders  matthew  annette  broadcast  \\\n",
       "0                0       0          0       0        0        0          0   \n",
       "1                0       0          0       0        0        0          0   \n",
       "2                0       0          0       0        0        0          0   \n",
       "3                0       0          0       0        0        0          0   \n",
       "4                0       0          0       0        0        0          0   \n",
       "\n",
       "   fergus  investments  filmmaking  ...  nonus  infections  mbeki  \\\n",
       "0       0            0           0  ...      0           0      0   \n",
       "1       0            0           0  ...      0           0      0   \n",
       "2       0            0           0  ...      0           0      0   \n",
       "3       0            0           0  ...      0           0      0   \n",
       "4       0            0           0  ...      0           0      0   \n",
       "\n",
       "   illequipped  recognise  nowadays  dismounting  xabi  tossed  Category  \n",
       "0            0          0         0            0     0       0         0  \n",
       "1            0          0         0            0     0       0         0  \n",
       "2            0          0         0            0     0       0         0  \n",
       "3            0          0         0            0     0       0         0  \n",
       "4            0          0         0            0     0       0         0  \n",
       "\n",
       "[5 rows x 31121 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagofwords_and_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876587f",
   "metadata": {},
   "source": [
    "## Naive Bayes Model SKlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e6a6b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#Model Building\n",
    "classifier = MultinomialNB()\n",
    "#classifier.fit(x_train,y_train)\n",
    "classifier.fit(np.array(bagofwords_df),np.array(y1).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99b866f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text):\n",
    "    # This gets the numbered outputs of the Naive Bayes' method and returns them to their named classes\n",
    "    prediction = []\n",
    "    pred = classifier.predict(text)\n",
    "    for best_label in pred:\n",
    "        if best_label == 0:\n",
    "            prediction.append('business')\n",
    "        elif best_label == 1:\n",
    "            prediction.append('entertainment')\n",
    "        elif best_label == 2:\n",
    "            prediction.append('politics')\n",
    "        elif best_label  == 3:\n",
    "            prediction.append('sport')\n",
    "        else:\n",
    "            prediction.append('tech')\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87892b5f",
   "metadata": {},
   "source": [
    "### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be10caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagofwords_test = wordtomat(remove_ws(np.array(article_test_string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b72c152f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31110</th>\n",
       "      <th>31111</th>\n",
       "      <th>31112</th>\n",
       "      <th>31113</th>\n",
       "      <th>31114</th>\n",
       "      <th>31115</th>\n",
       "      <th>31116</th>\n",
       "      <th>31117</th>\n",
       "      <th>31118</th>\n",
       "      <th>31119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "1      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "2      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "3      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "4      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "   31110  31111  31112  31113  31114  31115  31116  31117  31118  31119  \n",
       "0      0      0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 31120 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bagofwords_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c27c6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = prediction(bagofwords_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8650d9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'tech', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'politics', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'tech', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'tech', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'entertainment', 'politics', 'business', 'politics', 'politics', 'politics', 'politics', 'politics', 'entertainment', 'politics', 'politics', 'tech', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'business', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'politics', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'politics', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'sport', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'entertainment', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'tech', 'politics', 'tech', 'tech']\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7a1885a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n",
      "0      business\n",
      "1      business\n",
      "2      business\n",
      "3      business\n",
      "4      business\n",
      "         ...   \n",
      "218        tech\n",
      "219        tech\n",
      "220        tech\n",
      "221        tech\n",
      "222        tech\n",
      "Name: category, Length: 223, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(len(pred))\n",
    "print(article_test_Categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c83363b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33: business and tech\n",
      "66: entertainment and politics\n",
      "75: entertainment and tech\n",
      "84: entertainment and tech\n",
      "91: politics and business\n",
      "97: politics and entertainment\n",
      "100: politics and tech\n",
      "117: politics and business\n",
      "163: sport and politics\n",
      "210: tech and entertainment\n",
      "220: tech and politics\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 1 represents a correct prediction, 0 represents an incorrect prediction\n",
    "array = np.zeros(len(pred))\n",
    "for i in range(len(pred)):\n",
    "    if(article_test_Categories[i] == pred[i]):\n",
    "        array[i] = 1\n",
    "    else:\n",
    "        print(str(i) + \": \" + article_test_Categories[i] + \" and \" + pred[i])\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69ba222c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes' prediction is 95.06726457399103 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the Naive Bayes' prediction is\",sum(array)*100/len(array),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d552888b",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a444db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Binary classification for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66b27dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 copies of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "839fe912",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = np.unique(bagofwords_and_cat.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a79b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = bagofwords_and_cat.copy()\n",
    "d1 = bagofwords_and_cat.copy()\n",
    "d2 = bagofwords_and_cat.copy()\n",
    "d3 = bagofwords_and_cat.copy()\n",
    "d4 = bagofwords_and_cat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1ca145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [d0,d1,d2,d3,d4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2839c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn each dataset into a binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69b23c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(categories)):\n",
    "    for j in range(d0.shape[0]):\n",
    "        if datasets[i].at[j,'Category'] == i:\n",
    "            datasets[i].at[j,'Category'] = 1\n",
    "        else:\n",
    "            datasets[i].at[j,'Category'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc925484",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTest_datadict = {}\n",
    "for i in range(len(categories)):\n",
    "    X = datasets[i].iloc[:,:-1]\n",
    "    X = X.T\n",
    "    y = datasets[i].iloc[:,-1]\n",
    "    y = np.array(y)\n",
    "    TrainTest_datadict['D'+str(i)] = [X,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7dbd34c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for dataset 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iteration number: 20\n",
      "iteration number: 21\n",
      "iteration number: 22\n",
      "iteration number: 23\n",
      "iteration number: 24\n",
      "iteration number: 25\n",
      "iteration number: 26\n",
      "iteration number: 27\n",
      "iteration number: 28\n",
      "iteration number: 29\n",
      "iteration number: 30\n",
      "iteration number: 31\n",
      "iteration number: 32\n",
      "iteration number: 33\n",
      "iteration number: 34\n",
      "iteration number: 35\n",
      "iteration number: 36\n",
      "iteration number: 37\n",
      "iteration number: 38\n",
      "iteration number: 39\n",
      "iteration number: 40\n",
      "iteration number: 41\n",
      "iteration number: 42\n",
      "iteration number: 43\n",
      "iteration number: 44\n",
      "iteration number: 45\n",
      "iteration number: 46\n",
      "iteration number: 47\n",
      "iteration number: 48\n",
      "iteration number: 49\n",
      "iteration number: 50\n",
      "iteration number: 51\n",
      "iteration number: 52\n",
      "iteration number: 53\n",
      "iteration number: 54\n",
      "iteration number: 55\n",
      "iteration number: 56\n",
      "iteration number: 57\n",
      "iteration number: 58\n",
      "iteration number: 59\n",
      "iteration number: 60\n",
      "iteration number: 61\n",
      "iteration number: 62\n",
      "iteration number: 63\n",
      "iteration number: 64\n",
      "iteration number: 65\n",
      "iteration number: 66\n",
      "iteration number: 67\n",
      "iteration number: 68\n",
      "iteration number: 69\n",
      "iteration number: 70\n",
      "iteration number: 71\n",
      "iteration number: 72\n",
      "iteration number: 73\n",
      "iteration number: 74\n",
      "iteration number: 75\n",
      "iteration number: 76\n",
      "iteration number: 77\n",
      "iteration number: 78\n",
      "iteration number: 79\n",
      "iteration number: 80\n",
      "iteration number: 81\n",
      "iteration number: 82\n",
      "iteration number: 83\n",
      "iteration number: 84\n",
      "iteration number: 85\n",
      "iteration number: 86\n",
      "iteration number: 87\n",
      "iteration number: 88\n",
      "iteration number: 89\n",
      "iteration number: 90\n",
      "iteration number: 91\n",
      "iteration number: 92\n",
      "iteration number: 93\n",
      "iteration number: 94\n",
      "iteration number: 95\n",
      "iteration number: 96\n",
      "iteration number: 97\n",
      "iteration number: 98\n",
      "iteration number: 99\n",
      "iteration number: 100\n",
      "Training for dataset 1\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iteration number: 20\n",
      "iteration number: 21\n",
      "iteration number: 22\n",
      "iteration number: 23\n",
      "iteration number: 24\n",
      "iteration number: 25\n",
      "iteration number: 26\n",
      "iteration number: 27\n",
      "iteration number: 28\n",
      "iteration number: 29\n",
      "iteration number: 30\n",
      "iteration number: 31\n",
      "iteration number: 32\n",
      "iteration number: 33\n",
      "iteration number: 34\n",
      "iteration number: 35\n",
      "iteration number: 36\n",
      "iteration number: 37\n",
      "iteration number: 38\n",
      "iteration number: 39\n",
      "iteration number: 40\n",
      "iteration number: 41\n",
      "iteration number: 42\n",
      "iteration number: 43\n",
      "iteration number: 44\n",
      "iteration number: 45\n",
      "iteration number: 46\n",
      "iteration number: 47\n",
      "iteration number: 48\n",
      "iteration number: 49\n",
      "iteration number: 50\n",
      "iteration number: 51\n",
      "iteration number: 52\n",
      "iteration number: 53\n",
      "iteration number: 54\n",
      "iteration number: 55\n",
      "iteration number: 56\n",
      "iteration number: 57\n",
      "iteration number: 58\n",
      "iteration number: 59\n",
      "iteration number: 60\n",
      "iteration number: 61\n",
      "iteration number: 62\n",
      "iteration number: 63\n",
      "iteration number: 64\n",
      "iteration number: 65\n",
      "iteration number: 66\n",
      "iteration number: 67\n",
      "iteration number: 68\n",
      "iteration number: 69\n",
      "iteration number: 70\n",
      "iteration number: 71\n",
      "iteration number: 72\n",
      "iteration number: 73\n",
      "iteration number: 74\n",
      "iteration number: 75\n",
      "iteration number: 76\n",
      "iteration number: 77\n",
      "iteration number: 78\n",
      "iteration number: 79\n",
      "iteration number: 80\n",
      "iteration number: 81\n",
      "iteration number: 82\n",
      "iteration number: 83\n",
      "iteration number: 84\n",
      "iteration number: 85\n",
      "iteration number: 86\n",
      "iteration number: 87\n",
      "iteration number: 88\n",
      "iteration number: 89\n",
      "iteration number: 90\n",
      "iteration number: 91\n",
      "iteration number: 92\n",
      "iteration number: 93\n",
      "iteration number: 94\n",
      "iteration number: 95\n",
      "iteration number: 96\n",
      "iteration number: 97\n",
      "iteration number: 98\n",
      "iteration number: 99\n",
      "iteration number: 100\n",
      "Training for dataset 2\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iteration number: 20\n",
      "iteration number: 21\n",
      "iteration number: 22\n",
      "iteration number: 23\n",
      "iteration number: 24\n",
      "iteration number: 25\n",
      "iteration number: 26\n",
      "iteration number: 27\n",
      "iteration number: 28\n",
      "iteration number: 29\n",
      "iteration number: 30\n",
      "iteration number: 31\n",
      "iteration number: 32\n",
      "iteration number: 33\n",
      "iteration number: 34\n",
      "iteration number: 35\n",
      "iteration number: 36\n",
      "iteration number: 37\n",
      "iteration number: 38\n",
      "iteration number: 39\n",
      "iteration number: 40\n",
      "iteration number: 41\n",
      "iteration number: 42\n",
      "iteration number: 43\n",
      "iteration number: 44\n",
      "iteration number: 45\n",
      "iteration number: 46\n",
      "iteration number: 47\n",
      "iteration number: 48\n",
      "iteration number: 49\n",
      "iteration number: 50\n",
      "iteration number: 51\n",
      "iteration number: 52\n",
      "iteration number: 53\n",
      "iteration number: 54\n",
      "iteration number: 55\n",
      "iteration number: 56\n",
      "iteration number: 57\n",
      "iteration number: 58\n",
      "iteration number: 59\n",
      "iteration number: 60\n",
      "iteration number: 61\n",
      "iteration number: 62\n",
      "iteration number: 63\n",
      "iteration number: 64\n",
      "iteration number: 65\n",
      "iteration number: 66\n",
      "iteration number: 67\n",
      "iteration number: 68\n",
      "iteration number: 69\n",
      "iteration number: 70\n",
      "iteration number: 71\n",
      "iteration number: 72\n",
      "iteration number: 73\n",
      "iteration number: 74\n",
      "iteration number: 75\n",
      "iteration number: 76\n",
      "iteration number: 77\n",
      "iteration number: 78\n",
      "iteration number: 79\n",
      "iteration number: 80\n",
      "iteration number: 81\n",
      "iteration number: 82\n",
      "iteration number: 83\n",
      "iteration number: 84\n",
      "iteration number: 85\n",
      "iteration number: 86\n",
      "iteration number: 87\n",
      "iteration number: 88\n",
      "iteration number: 89\n",
      "iteration number: 90\n",
      "iteration number: 91\n",
      "iteration number: 92\n",
      "iteration number: 93\n",
      "iteration number: 94\n",
      "iteration number: 95\n",
      "iteration number: 96\n",
      "iteration number: 97\n",
      "iteration number: 98\n",
      "iteration number: 99\n",
      "iteration number: 100\n",
      "Training for dataset 3\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iteration number: 20\n",
      "iteration number: 21\n",
      "iteration number: 22\n",
      "iteration number: 23\n",
      "iteration number: 24\n",
      "iteration number: 25\n",
      "iteration number: 26\n",
      "iteration number: 27\n",
      "iteration number: 28\n",
      "iteration number: 29\n",
      "iteration number: 30\n",
      "iteration number: 31\n",
      "iteration number: 32\n",
      "iteration number: 33\n",
      "iteration number: 34\n",
      "iteration number: 35\n",
      "iteration number: 36\n",
      "iteration number: 37\n",
      "iteration number: 38\n",
      "iteration number: 39\n",
      "iteration number: 40\n",
      "iteration number: 41\n",
      "iteration number: 42\n",
      "iteration number: 43\n",
      "iteration number: 44\n",
      "iteration number: 45\n",
      "iteration number: 46\n",
      "iteration number: 47\n",
      "iteration number: 48\n",
      "iteration number: 49\n",
      "iteration number: 50\n",
      "iteration number: 51\n",
      "iteration number: 52\n",
      "iteration number: 53\n",
      "iteration number: 54\n",
      "iteration number: 55\n",
      "iteration number: 56\n",
      "iteration number: 57\n",
      "iteration number: 58\n",
      "iteration number: 59\n",
      "iteration number: 60\n",
      "iteration number: 61\n",
      "iteration number: 62\n",
      "iteration number: 63\n",
      "iteration number: 64\n",
      "iteration number: 65\n",
      "iteration number: 66\n",
      "iteration number: 67\n",
      "iteration number: 68\n",
      "iteration number: 69\n",
      "iteration number: 70\n",
      "iteration number: 71\n",
      "iteration number: 72\n",
      "iteration number: 73\n",
      "iteration number: 74\n",
      "iteration number: 75\n",
      "iteration number: 76\n",
      "iteration number: 77\n",
      "iteration number: 78\n",
      "iteration number: 79\n",
      "iteration number: 80\n",
      "iteration number: 81\n",
      "iteration number: 82\n",
      "iteration number: 83\n",
      "iteration number: 84\n",
      "iteration number: 85\n",
      "iteration number: 86\n",
      "iteration number: 87\n",
      "iteration number: 88\n",
      "iteration number: 89\n",
      "iteration number: 90\n",
      "iteration number: 91\n",
      "iteration number: 92\n",
      "iteration number: 93\n",
      "iteration number: 94\n",
      "iteration number: 95\n",
      "iteration number: 96\n",
      "iteration number: 97\n",
      "iteration number: 98\n",
      "iteration number: 99\n",
      "iteration number: 100\n",
      "Training for dataset 4\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iteration number: 20\n",
      "iteration number: 21\n",
      "iteration number: 22\n",
      "iteration number: 23\n",
      "iteration number: 24\n",
      "iteration number: 25\n",
      "iteration number: 26\n",
      "iteration number: 27\n",
      "iteration number: 28\n",
      "iteration number: 29\n",
      "iteration number: 30\n",
      "iteration number: 31\n",
      "iteration number: 32\n",
      "iteration number: 33\n",
      "iteration number: 34\n",
      "iteration number: 35\n",
      "iteration number: 36\n",
      "iteration number: 37\n",
      "iteration number: 38\n",
      "iteration number: 39\n",
      "iteration number: 40\n",
      "iteration number: 41\n",
      "iteration number: 42\n",
      "iteration number: 43\n",
      "iteration number: 44\n",
      "iteration number: 45\n",
      "iteration number: 46\n",
      "iteration number: 47\n",
      "iteration number: 48\n",
      "iteration number: 49\n",
      "iteration number: 50\n",
      "iteration number: 51\n",
      "iteration number: 52\n",
      "iteration number: 53\n",
      "iteration number: 54\n",
      "iteration number: 55\n",
      "iteration number: 56\n",
      "iteration number: 57\n",
      "iteration number: 58\n",
      "iteration number: 59\n",
      "iteration number: 60\n",
      "iteration number: 61\n",
      "iteration number: 62\n",
      "iteration number: 63\n",
      "iteration number: 64\n",
      "iteration number: 65\n",
      "iteration number: 66\n",
      "iteration number: 67\n",
      "iteration number: 68\n",
      "iteration number: 69\n",
      "iteration number: 70\n",
      "iteration number: 71\n",
      "iteration number: 72\n",
      "iteration number: 73\n",
      "iteration number: 74\n",
      "iteration number: 75\n",
      "iteration number: 76\n",
      "iteration number: 77\n",
      "iteration number: 78\n",
      "iteration number: 79\n",
      "iteration number: 80\n",
      "iteration number: 81\n",
      "iteration number: 82\n",
      "iteration number: 83\n",
      "iteration number: 84\n",
      "iteration number: 85\n",
      "iteration number: 86\n",
      "iteration number: 87\n",
      "iteration number: 88\n",
      "iteration number: 89\n",
      "iteration number: 90\n",
      "iteration number: 91\n",
      "iteration number: 92\n",
      "iteration number: 93\n",
      "iteration number: 94\n",
      "iteration number: 95\n",
      "iteration number: 96\n",
      "iteration number: 97\n",
      "iteration number: 98\n",
      "iteration number: 99\n",
      "iteration number: 100\n"
     ]
    }
   ],
   "source": [
    "iterations = 100 # large number\n",
    "alpha = 0.01\n",
    "m = d0.shape[1]\n",
    "cost_values = []\n",
    "trained_parameters = []\n",
    "\n",
    "for trainsets in range(len(categories)):\n",
    "    X = TrainTest_datadict['D'+str(trainsets)][0]\n",
    "    y = TrainTest_datadict['D'+str(trainsets)][1]\n",
    "    weights = np.full((1,X.shape[0]),0.01)\n",
    "    bias = 0\n",
    "    costfunc_values = []\n",
    "    k = 0\n",
    "    print('Training for dataset '+str(trainsets))\n",
    "    for i in range(1,iterations+1):\n",
    "        # logistic function\n",
    "        z = np.dot(weights,X) + bias\n",
    "        hypothesis = 1/(1+np.exp(-z))\n",
    "        \n",
    "        # Cost function\n",
    "        j = 1/m *(-1*(np.sum(y*np.log(hypothesis) + (1-y)*np.log(1-hypothesis))))\n",
    "        costfunc_values.append(j)\n",
    "        k+=1\n",
    "        \n",
    "        # Gradient decent\n",
    "        \n",
    "        dw = 1/m * np.dot(hypothesis-y,X.T)\n",
    "        db = 1/m * np.sum(hypothesis-y)\n",
    "        weights = weights - alpha*dw\n",
    "        bias = bias - alpha*db\n",
    "        \n",
    "        # stop training\n",
    "        if i%2000 == 0:\n",
    "            print('running @',j)\n",
    "        if i%2 == 0:\n",
    "            if abs(j-costfunc_values[-2])<0.000001:\n",
    "                if abs(j-costfunc_values[-3])<0.000001:\n",
    "                    break\n",
    "        \n",
    "        cost_values.append(costfunc_values)\n",
    "        trained_parameters.append([weights,bias])\n",
    "        print('iteration number:',k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7767cc8",
   "metadata": {},
   "source": [
    "### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9cf55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(bagofwords_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8d730a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(trained_parameters,test):\n",
    "    inputs = test.T\n",
    "    result = []\n",
    "    prediction = []\n",
    "    print(inputs.shape[1])\n",
    "    for i in range(inputs.shape[1]):\n",
    "        probabilities = []\n",
    "        for j in range(5):\n",
    "            weights = trained_parameters[j][0]\n",
    "            bias = trained_parameters[j][1]\n",
    "            z = np.dot(weights,(inputs.iloc[:,i]).T)+bias\n",
    "            hypothesis = 1/(1+np.exp(-z))\n",
    "            probabilities.append(hypothesis)\n",
    "        predict = probabilities.index(max(probabilities))\n",
    "        result.append(predict)\n",
    "    for best_label in result:\n",
    "        if best_label == 0:\n",
    "            prediction.append('business')\n",
    "        elif best_label == 1:\n",
    "            prediction.append('entertainment')\n",
    "        elif best_label == 2:\n",
    "            prediction.append('politics')\n",
    "        elif best_label  == 3:\n",
    "            prediction.append('sport')\n",
    "        else:\n",
    "            prediction.append('tech')\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1327dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "pred = prediction(trained_parameters,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e12b288a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business', 'business']\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21975476",
   "metadata": {},
   "source": [
    "There seems to be an error with the multinomial logisitic regression attempt. It only outputs business."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
